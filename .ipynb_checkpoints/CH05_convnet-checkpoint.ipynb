{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH05_convnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonghyun-2/Keras/blob/master/CH05_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYwyWq4ZzCOP",
        "colab_type": "text"
      },
      "source": [
        "###  5.1 합성곱 신경망(convolutional neural network) (컨브넷convnet) 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNReGUdKzCOR",
        "colab_type": "text"
      },
      "source": [
        "컴퓨터 비전 애플리케이션에 사용되는 딥러닝 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs-ndn5TzCOS",
        "colab_type": "text"
      },
      "source": [
        "2장에서의 densely connected network에서 사용한 MNIST 숫자 이미지 분류를 컨브넷에 적용하는 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f44ehpDezCOT",
        "colab_type": "code",
        "outputId": "4bf1e9ba-aa10-49f8-cfe8-e3aef4b3350a",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jong_Hyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQSmAmYKzCOa",
        "colab_type": "text"
      },
      "source": [
        "컨브넷은 (image_height, image_width, image_channels)크기의 입력텐서 사용\n",
        "\n",
        "MNIST이미지 포맷 (28,28,1)크기의 입력 처리 하기위해 첫번째 층의 매개변수로 \n",
        "\n",
        "input_shape = (28,28,1) 전달"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WPACRLrzCOb",
        "colab_type": "text"
      },
      "source": [
        "지금까지의 convnet의 구조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-maCQKzCOc",
        "colab_type": "code",
        "outputId": "00c801ab-3c95-4fdd-c744-ca1a4ce98af0",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbMnlIlbzCOg",
        "colab_type": "text"
      },
      "source": [
        "conv2d와 maxpooling2d층의 출력은 (height, width, channels) 크기의 3D 텐서이고. 높이와 넓이 차원은 네트워크가 깊어질수록 작아지는 경향이 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YxWcP54zCOh",
        "colab_type": "text"
      },
      "source": [
        "다음 단계에서 마지막 층의 ((3, 3, 64) 크기인) 출력 텐서를 완전 연결 네트워크에 주입\n",
        "\n",
        "이 분류기는 1D벡터 처리지만 전층 벡터는 3D 텐서 3D -> 1D 로 펼쳐야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2Y78aUzCOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQvQuKLVzCOl",
        "colab_type": "code",
        "outputId": "e21119d8-2532-4d54-c107-2d81e3393ef4",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcSerSUUzCOp",
        "colab_type": "text"
      },
      "source": [
        "5번째 output shape가 (3,3,64) 에서 (576)으로 바뀐것을 볼수있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2G89MX3zCOq",
        "colab_type": "text"
      },
      "source": [
        "MNIST 이미지를 이용해 convnet 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3bPukXWEzCOr",
        "colab_type": "code",
        "outputId": "0d8c1d26-b1f2-4e67-d8ca-3327008f3620",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000,28,28,1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000,28,28,1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5,batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Jong_Hyun\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXovDECxzCOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_image, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9itGmsZzCOz",
        "colab_type": "text"
      },
      "source": [
        "실행 시킬경우 0.987의 정확도가 나옴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFPB723szCO0",
        "colab_type": "text"
      },
      "source": [
        "## 5.1.1 합성곱연산\n",
        "\n",
        "---\n",
        "\n",
        "완전연결층(densely connected network)와 합성곱(convolutional neural network)의 차이 : \n",
        "\n",
        "Dense 층 : 입력 특성 공간에 있는 전역 패턴을 학습\n",
        "\n",
        "합성곱 층: 지역 패턴을 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12KQEL_6zCO1",
        "colab_type": "text"
      },
      "source": [
        "convnet의 두가지 성질\n",
        "\n",
        "1. 학습된 패턴은 평행 이동 불변성(translation invariant)을 가짐\n",
        "   컨브넷이 이미지의 오른쪽 아래에서 어떤 패턴을 학습할경우 다른곳 에서도 패턴 인식가능\n",
        "   완전연결층은 새롭게 학습해야함\n",
        "   이미지를 효율적으로 처리하게 만들어줌\n",
        "   적은 수의 훈련 샘플 사용 일반화 능력을 가진 표현을 학습할수 있음.\n",
        "2. 패턴의 공간적 계층 구조를 학습 할 수 있음.\n",
        "   첫번째 CNN층은 작은 지역의 패턴을 학습\n",
        "   두번째 CNN층은 첫번째 층의 특성으로 구성된 큰 패턴 학습\n",
        "   이런 방식으로 복잡하고 추상적인 시각적 개념을 학습 가능\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lguJMyRUzCO2",
        "colab_type": "text"
      },
      "source": [
        "CNN은 특성맵(feature map)이라 부르는 텐서에 적용\n",
        "\n",
        "이텐서는 2개의 공간(높이, 넓이)축 과 깊이(채널) 축으로 구성\n",
        "\n",
        "RGB = 3컬러채널\n",
        "\n",
        "그레이스케일 = 1채널"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceZFCkk9zCO3",
        "colab_type": "text"
      },
      "source": [
        "CNN은 입력 특성 맵(input feature map)에서 작은 패치(patch)들 추출 모든 패치에 같은 변환을 적용 출력 특성 맵(output feature map) 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4uXMdJDzCO3",
        "colab_type": "text"
      },
      "source": [
        "output feature map 도 높이 넓이 그리고 필터로 구성된 3D 텐서\n",
        "\n",
        "필터는 입력 데이터의 어떤 특성을 인코딩\n",
        "예) 하나의 필터가 입력에 얼굴이 있는지를 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qczi24PIzCO4",
        "colab_type": "text"
      },
      "source": [
        "예제 첫번째 layer \n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (28,28,1)))\n",
        "\n",
        "(28,28,1) 크기의 입력 (26,26,32) 크기의 출력\n",
        "\n",
        "즉 32개의 필터를 적용 각각은 26 * 26 크기의 배열 값을 가짐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aoc-OyCHzCO5",
        "colab_type": "text"
      },
      "source": [
        "합성곱의 2가지 파라미터\n",
        "1. 입력으로 부터 뽑아낼 패치의 크기 3 * 3 or 5 * 5\n",
        "2. 특성 맵의 출력 깊이 필터의 수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYlwM9GKzCO6",
        "colab_type": "text"
      },
      "source": [
        "model.add(layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (28,28,1)))\n",
        "\n",
        "패치\n",
        "3 * 3 크기의 윈도우가 슬라이딩 하면서 3d 특성을 추출하는 방식으로 작동\n",
        "\n",
        "이런 3d 패치는 합성곱커널(convolution kernel)와의 곱을 통하여 1d 벡터로 변환\n",
        "\n",
        "출력 특성 맵의 공간상 위치는 입력 특성 맵의 같은 위치에 대응"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6_r8xw3zCO7",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08xAEJhNzCO8",
        "colab_type": "text"
      },
      "source": [
        "출력의 높이, 넓이는 입력의 높이, 넓이와 다를수 있음\n",
        "\n",
        "이유\n",
        "\n",
        "1. 경계문제 패딩(padding)을 추가하여 대응 가능\n",
        "2. 스트라이드의 사용여부"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ-2LOi7zCO8",
        "colab_type": "text"
      },
      "source": [
        "패딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlTLaQ9fzCO9",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPvKqZYXzCO-",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhIW70VtzCO_",
        "colab_type": "text"
      },
      "source": [
        "Conv2D 층에서 padding 매개변수로 설정 가능\n",
        "\n",
        "valid : 패딩 사용 안함\n",
        "\n",
        "same : 패딩 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8X0GftEzCPA",
        "colab_type": "text"
      },
      "source": [
        "스트라이드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kImuzJ0zCPB",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "http://ling.snu.ac.kr/class/cl_under1801/DL07-Convolutional%20Neural%20Network.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymECZF9PzCPB",
        "colab_type": "text"
      },
      "source": [
        "패딩을 키우면 출력크기가 커지고\n",
        "스트라이드를 키우면 출력크기가 작아짐"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJHGGtiizCPC",
        "colab_type": "text"
      },
      "source": [
        "## 5.1.2 maxpooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aygyKXKYzCPD",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "https://computersciencewiki.org/index.php/Max-pooling_/_Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6R5LJQuzCPE",
        "colab_type": "text"
      },
      "source": [
        "합성곱 : 전형적으로 3x3 윈도우와 스트라이드 1를 사용하여 다운샘플링\n",
        "\n",
        "maxpooling : 2x2 윈도우 스트라이드 2를 사용하여 다운샘플링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsT8ytbHzCPF",
        "colab_type": "text"
      },
      "source": [
        "다운 샘플링을 하지 않았을때의 문제점\n",
        "\n",
        "1. 마지막 합성곱 층의 특성이 전체 입력에 대한 정보를 가지고 있어야하는데 전체 입력의 일부분에 대한 정보만 가짐\n",
        "2. 최종 특성맵은 22x22x64 = 30976개의 가중치를 가짐 너무 많음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOYtP-JozCPF",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 소규모 데이터셋이세 밑바닥부터 컨브넷 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvYAyh7DzCPG",
        "colab_type": "text"
      },
      "source": [
        "4000개의 고양이와 강이지 이미지 분류(2000고양이, 2000강아지)\n",
        "2000개 훈련, 1000개 검증, 1000개 테스트\n",
        "\n",
        "모델 훈련 순서 \n",
        "1. 2000개의 훈련 샘플에서 기준이되는 기본성능을 만들기(약 71% 정확도)\n",
        "2. 과대적합을 줄이기 위한 데이터증식(data augmentation) (약 82% 정확도)\n",
        "3. 사전 훈련된 네트워크로 특성을 추출, 사전 훈련된 네트워크를 세밀하게 튜닝(약 92% 정확도)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Zv3QykzCPH",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.2 데이터 내려받기\n",
        "\n",
        "---\n",
        "\n",
        "Dogs vs Cats\n",
        "\n",
        "https://www.kaggle.com/c/dogs-vs-cats/data 에서 다운로드 가능\n",
        "\n",
        "1000개의 훈련세트 500개의 검증세트 500개의 테스트 세트를 만드는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf9uDnYwzCPI",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "c38517c9-e7b5-4a54-8dea-df244862fad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "## 원본 데이터셋 압축해제한 디렉터리\n",
        "original_dataset_dir = 'D:\\\\datasets\\\\cats_and_dogs\\\\train\\\\train'\n",
        "\n",
        "## 소규모 데이터셋을 저장한 디렉터리\n",
        "base_dir = 'D:\\\\datasets\\\\cats_and_dogs_small'\n",
        "#os.mkdir(base_dir)\n",
        "\n",
        "## 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "#os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "#os.mkdir(validation_dir)\n",
        "test_dir=os.path.join(base_dir,'test')\n",
        "#os.mkdir(test_dir)\n",
        "\n",
        "## 훈련용 고양이 사진 디렉터리\n",
        "train_cats_dir = os.path.join(train_dir,'cats')\n",
        "#os.mkdir(train_cats_dir)\n",
        "\n",
        "## 훈련용 강아지 사진 디렉터리\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "#os.mkdir(train_dogs_dir)\n",
        "\n",
        "## 검증용 고양이 사진 디렉터리\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "#os.mkdir(validation_cats_dir)\n",
        "\n",
        "## 검증용 강아지 사진 디렉터리\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "#os.mkdir(validation_dogs_dir)\n",
        "\n",
        "## 테스트용 고양이 사진 디렉터리\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "#os.mkdir(test_cats_dir)\n",
        "\n",
        "## 테스트용 강아지 사진 디렉터리\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "#os.mkdir(test_dogs_dir)\n",
        "\n",
        "## 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
        "'''fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "## 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "## 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "## 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "## 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "## 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(train_cats_dir, fname)\\n    shutil.copyfile(src, dst)\\n\\n## 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(validation_cats_dir, fname)\\n    shutil.copyfile(src, dst)\\n    \\n## 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\\nfnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(test_cats_dir, fname)\\n    shutil.copyfile(src, dst)\\n    \\n## 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(train_dogs_dir, fname)\\n    shutil.copyfile(src, dst)\\n    \\n## 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(validation_dogs_dir, fname)\\n    shutil.copyfile(src, dst)\\n    \\n## 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\\nfor fname in fnames:\\n    src = os.path.join(original_dataset_dir, fname)\\n    dst = os.path.join(test_dogs_dir, fname)\\n    shutil.copyfile(src, dst)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ptiBlFzCPM",
        "colab_type": "text"
      },
      "source": [
        "이후에 사진의 개수를 카운트 할경우\n",
        "\n",
        "훈련용 고양이 이미지 전체개수 : 1000<br>\n",
        "훈련용 강아지 이미지 전체개수 : 1000\n",
        "\n",
        "검증용 고양이, 강아지 이미지 전체개수: 각 500개<br>\n",
        "테스트용 고양이, 강아지 이미지 전체개수 : 각 500개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzbtzciHzCPN",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.3 네트워크 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTZzrlKZzCPP",
        "colab_type": "text"
      },
      "source": [
        "4개의 Conv3D 와 3개의 Maxpooling2D 층을 번갈아 쌓은 컨브넷 구성\n",
        "\n",
        "150x150 크기의 입력에서 flatten층 이전에 7x7 크기의 특성 맵으로 줄어듬\n",
        "\n",
        "* 특성맵의 깊이는 네트워크에서 점진적으로 증가 특성맵의 크기는 감소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyyfIesv6XFr",
        "colab_type": "text"
      },
      "source": [
        "코드 5-5, 5-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batFj_ZY5oTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnyOJ8avzCPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation= 'relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss ='binary_crossentropy',\n",
        "             optimizer = optimizers.RMSprop(lr = 1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQqjGqeNzCPa",
        "colab_type": "code",
        "outputId": "42b1cae1-f43f-45a6-be8a-b1b8fca6c302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dnnRaIQzCPe",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.4 데이터 전처리\n",
        "\n",
        "---\n",
        "\n",
        "다운로드 받은 사진은 JPEG파일 이므로 네트워크에 주입되기전에 전처리를 해야함\n",
        "\n",
        "1. 사진파일을 읽음\n",
        "2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩\n",
        "3. float의 텐서로 변환\n",
        "4. 픽셀값(0~255) 의 스케일을 (0~1) 사이로 조정 (신경망은 작은 입력값 선호)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKgl4zmhzCPf",
        "colab_type": "text"
      },
      "source": [
        "케라스의 keras.preprocessing.image 에 ImageDataGenerator 클래스에서 이미지 파일을 전처리된 텐서로 바꾸어주는 파이썬 제너레이터 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zOjL0yazCPi",
        "colab_type": "text"
      },
      "source": [
        "파이썬 제너레이터는 반복자 처럼 작동하는 객체 for in 연산자에 사용가능 <br>\n",
        "yield연산자 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8470gnhMzCPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF5mDmz25_S8",
        "colab_type": "text"
      },
      "source": [
        "코드 5-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q27IQl72zCPm",
        "colab_type": "code",
        "outputId": "ab965df0-83cf-4a0f-b911-6b77d9be83e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S09-QWa4zCPo",
        "colab_type": "text"
      },
      "source": [
        "제너레이터의 출력은 150x150 RGB 이미지의 배치 (20,150,150,3), 이진 레이블배치(20,)크기로 이뤄짐 각 배치에 20개의 샘플이 존재 제너레이터는 break를 사용하지 않으면 끝없이 반복하여 break 문 사용 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwcr_OqmzCPp",
        "colab_type": "text"
      },
      "source": [
        "fit_generator 메서드를 사용할경우 제너레이터를 사용할 수 있음\n",
        "하나의 에포크를 정의하기 위해 제너레이터로부터 얼마나 많은 샘플을 뽑을것인지 지정해야함<br>\n",
        "steps_per_epoch 에서 설정가능<br>\n",
        "위에서 batch_size 가 20이므로 2000개의 샘플을 처리하기 위해선 100개의 steps_per_epoch 가 필요함<br>\n",
        "\n",
        "validation의 경우 1000개의 데이터를 사용하기위해 50개의 step가 필요\n",
        "(20 * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPHebIjAzCPq",
        "colab_type": "text"
      },
      "source": [
        "코드 5-8 모델 훈련하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6cGMX8fzCPq",
        "colab_type": "code",
        "outputId": "4fd82aa7-57f6-40bd-d4ff-50fde5e23d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch =100,\n",
        "      epochs = 30,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps = 50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f79a80b8be30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       validation_steps = 50)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_index_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM57BQoo6Gsk",
        "colab_type": "text"
      },
      "source": [
        "코드 5-9 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inlMzieazCPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cats_and_dogs_samll_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_QYTMWdzCPw",
        "colab_type": "text"
      },
      "source": [
        "코드 5-10 훈련데이터와 검증 데이터에 대한 모델의 손실, 정확도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2xTr-sfzCPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label = 'Training Acc')\n",
        "plt.plot(epochs, val_acc, 'b', label= 'Validation Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training Acc')\n",
        "plt.plot(epochs, val_loss, 'b', label= 'Validation Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXsssgy-zCP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-JB_jRuzCP2",
        "colab_type": "text"
      },
      "source": [
        "### 5.2.5 데이터 증식 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5v6nK0izCP5",
        "colab_type": "text"
      },
      "source": [
        "과대 적합은 학습할 샘플이 너무 적어 일반화 할 수 있는 모델을 훈련 시킬 수 없기 때문에 발생\n",
        "\n",
        "데이터 증식은 기존 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법\n",
        "\n",
        "ImageDataGenerator 가 여러 종류의 랜덤 변환을 적용하도록 설정 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et8Kqi5PzCP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYdQMj6AzCP7",
        "colab_type": "text"
      },
      "source": [
        "2. rotation -> 회전\n",
        "3,4. 수평, 수직 이동범위\n",
        "5.랜덤하게 왜곡시킬 각도 범위\n",
        "6. 랜덤하게 사진 확대\n",
        "7. 수평으로 화면을 뒤집음\n",
        "8. 회전이나 가로 세로 이동으로 인해 새롭게 생성해야 할 픽셀을 채우는 법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxQep4gzCP8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZ5-yP0zCP8",
        "colab_type": "text"
      },
      "source": [
        "증식된 이미지 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyKHCFeNXmUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3909bbd2-f268-4662-b4c8-532e505d9147"
      },
      "source": [
        "len(fnames)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H4iF2FqzCP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "521da652-7820-44eb-9025-cc2321da101b"
      },
      "source": [
        "# 이미지 전처리 유틸리티 모듈\n",
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = sorted([os.path.join(train_cats_dir,cat.num.jpg) for num in os.listdir(train_cats_dir)])\n",
        "\n",
        "#증식할 이미지 선택\n",
        "img_path = fnames[0]\n",
        "\n",
        "#이미지를 읽고 크기를 변경\n",
        "img = image.load_img(img_path, target_size = (150,150))\n",
        "\n",
        "#(150,150,3) 크기의 넘파이배열로 변환\n",
        "x= image.img_to_array(img)\n",
        "#(1,150,150,3) 크기로 변환\n",
        "x = x.reshape((1,) + x.shpae)\n",
        "\n",
        "#랜덤 이미지를 무한대로 뽑아내기위해 조건문을 사용하여 break 함\n",
        "i = 0\n",
        "for batch in datagen.flow(x,batch_size = 1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i%4 ==0:\n",
        "        break\n",
        "plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-6d16224a0fc0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    fnames[] = sorted([os.path.join(train_cats_dir,cat.num.jpg) for num in os.listdir(train_cats_dir)])\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eccgdgfiMIZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeHOpFv8iE3h",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YZA0r2jzCQC",
        "colab_type": "text"
      },
      "source": [
        "이미지 증식을 할경우 샘플은 늘어나지만 샘플간의 상호 연관성이 커서 모자란 샘플을 채워주기에 부족할수 있음 \n",
        "\n",
        "완전 연결 분류기 직전에 Dropout 층 추가 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiw6e3C9zCQD",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDZ55m6BzCQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f9e90927-db0b-42b0-936d-8d8be3987aa8"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape = (150,150,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss ='binary_crossentropy',\n",
        "             optimizer = optimizers.RMSprop(lr = 1e-4),\n",
        "             metrics=['acc'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Y7X6oxzCQH",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7SuGO0zzCQI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D9znlrwkpWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP08CsQPzCQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e5fe05de-c95f-48b3-9774-2abf92d97f9b"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "#검증 데이터는 증식 되면 안됨\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 100,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=50)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2d4ebe42c3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     validation_steps=50)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_index_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdbY4ZjBzCQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 저장\n",
        "model.save(cats_and_dogs_small_2.h5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IS-vVmYzCQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvWfUH3hzCQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGGUhj_MzCQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToKonEmPzCQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4uebJUdzCQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}